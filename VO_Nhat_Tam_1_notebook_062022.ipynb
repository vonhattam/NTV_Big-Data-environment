{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2825b25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 23:53:07.661384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-19 23:53:07.661421: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Librairies\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO, BytesIO\n",
    "import os\n",
    "import time\n",
    " \n",
    "# image\n",
    "from PIL import Image,ImageOps,ImageFilter\n",
    "\n",
    "# Fonctions pyspark\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType, IntegerType, DoubleType, DataType, FloatType\n",
    "from pyspark.ml.image import ImageSchema\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT, DenseVector\n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType\n",
    "\n",
    "# Librairie pour se connecter au service S3 d'AWS\n",
    "import boto3\n",
    "\n",
    "# transfer learning pour l'extraction des features\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc08a57",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1185608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retourne un dataFrame pyspark avec comme colonne la liste des chemins d'accès\n",
    "    de toutes les images se trouvant le dossier folder\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialisation du temps de calcul\n",
    "    start_time = time.time()\n",
    "    \n",
    "    lst_path =  []\n",
    "    \n",
    "    # connexion en local ou sur AWS\n",
    "    if local == 'True':\n",
    "\n",
    "        sub_folders = os.listdir(folder)\n",
    "        print(sub_folders)\n",
    "\n",
    "        for f in sub_folders:\n",
    "\n",
    "            lst_categ = os.listdir(folder + f)\n",
    "\n",
    "            for file in lst_categ:\n",
    "                lst_path.append(folder + f + \"/\" + file)\n",
    "    else :\n",
    "        # Connexion à l'espace de stockage S3 d'AWS\n",
    "        key=open('rootkey.txt','r')\n",
    "        wrd=key.read()\n",
    "        ID=str(wrd).split('\\n')[0]\n",
    "        PW=str(wrd).split('\\n')[1]\n",
    "        session = boto3.Session(aws_access_key_id=ID,\n",
    "                                aws_secret_access_key=PW)\n",
    "        s3_client = session.client(service_name='s3', region_name=\"us-east-1\")\n",
    "    \n",
    "\n",
    "\n",
    "        prefix = 'data'\n",
    "        sub_folders = s3_client.list_objects_v2(Bucket=\"ntv-p8\", Prefix=prefix)\n",
    "\n",
    "        for key in sub_folders[\"Contents\"]:\n",
    "\n",
    "            file = key[\"Key\"]\n",
    "            file = file.replace(prefix + \"/\", \"\")\n",
    "            lst_path.append(folder + file)\n",
    "\n",
    "    print(\"Nombre d'images chargées :\", len(lst_path))\n",
    "    \n",
    "    # Création d'un RDD à partit de la liste des chemins d'accès aux images\n",
    "    rdd = sc.parallelize(lst_path)\n",
    "    row_rdd = rdd.map(lambda x: Row(x))\n",
    "    \n",
    "    # Création d'un dataFrame pyspark à partir d'un RDD\n",
    "    df = spark.createDataFrame(row_rdd, [\"path_img\"])\n",
    "\n",
    "    # Affichage du temps de calcul\n",
    "    print(\"Temps d'execution {:.2f} secondes\".format(time.time() - start_time))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b159db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_categ(path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retourne le nom du dossier dans lequel se trouve l'image,\n",
    "    qui correspond au nom du type de fruits.\n",
    "    \"\"\"\n",
    "    \n",
    "    list_file = path.split(\"/\")\n",
    "    categ = list_file[-2]\n",
    "    \n",
    "    return categ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "118162cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "\n",
    "\n",
    "    # Traitement en mode local\n",
    "    if local == 'True':\n",
    "        \n",
    "        # fonction renvoie le même chemin d'accès\n",
    "        def get_path(img_path):\n",
    "            return img_path\n",
    "\n",
    "\n",
    "    # Traitement en mode AWS\n",
    "    else:\n",
    "        \n",
    "        # l'accès à S3 via la librairie boto3\n",
    "        def get_path(img_path):\n",
    "            key=open('rootkey.txt','r')\n",
    "            wrd=key.read()\n",
    "            ID=str(wrd).split('\\n')[0]\n",
    "            PW=str(wrd).split('\\n')[1]\n",
    "            session = boto3.Session(aws_access_key_id=ID,\n",
    "                                aws_secret_access_key=PW)\n",
    "            \n",
    "            img_path = img_path.replace(\"s3://ntv-p8/\", \"\")\n",
    "            s3 = session.resource(\"s3\", region_name='us-east-1')\n",
    "            bucket = s3.Bucket(\"ntv-p8\")\n",
    "            object = bucket.Object(img_path)\n",
    "            response = object.get()\n",
    "            stream = response['Body']\n",
    "            return stream\n",
    "\n",
    "        \n",
    "    # Ouvre l'image via la librairie pillow et prétraiter l'image\n",
    "    def preprocessing(img_path):\n",
    "        \n",
    "        img = Image.open(img_path).resize([20, 20])\n",
    "        img = ImageOps.autocontrast(img, cutoff=1)\n",
    "        img = ImageOps.equalize(img, mask = None) \n",
    "        image=img.filter(ImageFilter.GaussianBlur(radius=1))\n",
    "        return image\n",
    "\n",
    "    image = preprocessing(get_path(img_path))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33bcdbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    \"\"\"\n",
    "    Retourne un modèle ResNet50 avec la couche supérieure enlevée (fully-connected) et \n",
    "    des pondérations en broadcast déjà pré-entraînés. \n",
    "    On retire la couche supérieure car c'est celle qui permet de faire une classification, or \n",
    "    ici on se sert du modéle pour extraire des features.\n",
    "    \n",
    "    Pooling = \"avg\" est utilisé pour réduire le nombre de caractéristiques à 2048\n",
    "    \"\"\"\n",
    "\n",
    "    model = ResNet50(weights= None, include_top=False, pooling='avg')\n",
    "    #on ajoute les pondérations\n",
    "    model.set_weights(bc_model_weights.value)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "  \n",
    "def featurize_series(model, content_series):\n",
    "    \"\"\"\n",
    "    Retourne un pd.Series des features de l'image\n",
    "    \"\"\"\n",
    "    def preprocess(img_path):\n",
    "        result = preprocess_input(img_to_array(preprocess_image(img_path)))\n",
    "        return result\n",
    "                    \n",
    "    input = np.stack(content_series.map(preprocess))\n",
    "  # Extraction des features des images\n",
    "    preds = model.predict(input)\n",
    "                     \n",
    "  # Pour certaines couches, les caractéristiques de sortie sont des tensors multidimensionnels\n",
    "  # On aplatit les caractéristiques de tensors en vecteurs pour faciliter le stockage dans les dataframes Spark\n",
    "  # la fonction flatten() envoie une copie du tableau réduit à une seule dimension \n",
    "    output = [p.flatten() for p in preds]\n",
    "    return pd.Series(output)  \n",
    "\n",
    "@pandas_udf(ArrayType(FloatType()), PandasUDFType.SCALAR_ITER)\n",
    "\n",
    "def featurize_udf(content_series_iter):\n",
    "    '''\n",
    "    Cette méthode est un Itérateur Scalaire (pandas UDF signifiant User-Defined Functions) qui complète\n",
    "    la fonction de featurisation.\n",
    "    Cela renvoie une colonne Spark DataFrame de type ArrayType(FloatType).\n",
    "  \n",
    "    param content_series_iter : Cet argument est un itérateur sur des lots de données, où chaque lot\n",
    "    est une série de données d'images pandas.\n",
    "    '''\n",
    "    \n",
    "  # Avec les pandas UDF Scalar Iterator, on peut charger le modèle une fois et le réutiliser ensuite\n",
    "  # pour plusieurs lots de données. Cela permet d'amortir les frais liés au chargement de grands modèles.\n",
    "    model = model_fn()\n",
    "    for content_series in content_series_iter:\n",
    "        yield featurize_series(model, content_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4235bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Réduction dimensionnelle des images\n",
    "def reduction_dimension(df):\n",
    " \n",
    "    # Les données images sont converties au format vecteur dense\n",
    "    ud_f = udf(lambda r: Vectors.dense(r), VectorUDT())\n",
    "    df = df.withColumn('features', ud_f('features'))\n",
    "    \n",
    "    # Mise à l'échelle\n",
    "    standardizer = StandardScaler(inputCol=\"features\", outputCol=\"feature_scaler\",withStd=True, withMean=True)\n",
    "    model_std = standardizer.fit(df)\n",
    "    df = model_std.transform(df)\n",
    " \n",
    "    # Recherche nb de composante\n",
    "    num_components = 1000\n",
    "    pca = PCA(k = num_components,\n",
    "            inputCol=\"feature_scaler\", \n",
    "              outputCol=\"features_pca\")\n",
    " \n",
    "    reduc = pca.fit(df)\n",
    "    variance = reduc.explainedVariance\n",
    " \n",
    "    # visuel\n",
    "    plt.plot(np.arange(len(variance))+1, variance.cumsum(),c=\"red\",marker='o')\n",
    "    plt.xlabel(\"Nb de composantes\")\n",
    "    plt.ylabel(\"% variance\")\n",
    "    plt.show(block=False)\n",
    " \n",
    "    def nb_comp ():\n",
    "        for i in range(500):\n",
    "            a = variance.cumsum()[i]\n",
    "            if a >= 0.95:\n",
    "                print(\"{} composantes principales expliquent au moins 95% de la variance totale\".format(i))\n",
    "                break\n",
    "          \n",
    "        return i\n",
    " \n",
    "    n_comp=nb_comp()\n",
    " \n",
    "    # Réduction de dimention\n",
    "    pca = PCA(k=n_comp, inputCol='feature_scaler', outputCol='feature_reduit')\n",
    "    model_pca = pca.fit(df)\n",
    "    df = model_pca.transform(df)\n",
    " \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad20058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecrit les résultats en mode parquet\n",
    "\n",
    "def save_data(df):\n",
    "    # Initialisation du temps de calcul\n",
    "    start_time = time.time()\n",
    "    if local == 'True':\n",
    "        df_csv=df.toPandas()\n",
    "        df_csv.to_csv('results.csv')\n",
    "    else :\n",
    "        key=open('rootkey.txt','r')\n",
    "        wrd=key.read()\n",
    "        ID=str(wrd).split('\\n')[0]\n",
    "        PW=str(wrd).split('\\n')[1]\n",
    "        session = boto3.Session(aws_access_key_id=ID,\n",
    "                                aws_secret_access_key=PW)\n",
    "        df_csv=df.toPandas()\n",
    "        csv_buffer = StringIO()\n",
    "        df_csv.to_csv(csv_buffer)\n",
    "        s3_client =session.client(service_name='s3', region_name=\"us-east-1\")\n",
    "        s3_client.put_object(Body=csv_buffer.getvalue(),Bucket=\"ntv-p8\",Key='results')\n",
    "    # Affichage du temps de calcul\n",
    "    print(\"Temps d'execution {:.2f} secondes\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8786b3a",
   "metadata": {},
   "source": [
    "# Exécuter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f93bfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/06/19 23:53:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Démarre la session Spark\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc.setLogLevel('ERROR')\n",
    "spark = SparkSession.builder.appName(\"P8\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2a136fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-83-19.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d025e0d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Liste des images---\n",
      "Nombre d'images chargées : 546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'execution 4.37 secondes\n",
      "+-----------------------------------+\n",
      "|path_img                           |\n",
      "+-----------------------------------+\n",
      "|s3://ntv-p8/data/apple_6/r0_103.jpg|\n",
      "|s3://ntv-p8/data/apple_6/r0_107.jpg|\n",
      "|s3://ntv-p8/data/apple_6/r0_11.jpg |\n",
      "|s3://ntv-p8/data/apple_6/r0_111.jpg|\n",
      "|s3://ntv-p8/data/apple_6/r0_115.jpg|\n",
      "+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "----Extraction des catégories images-----\n",
      "Temps d'execution 0.08 secondes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+-------+\n",
      "|path_img                           |categ  |\n",
      "+-----------------------------------+-------+\n",
      "|s3://ntv-p8/data/apple_6/r0_103.jpg|apple_6|\n",
      "|s3://ntv-p8/data/apple_6/r0_107.jpg|apple_6|\n",
      "|s3://ntv-p8/data/apple_6/r0_11.jpg |apple_6|\n",
      "|s3://ntv-p8/data/apple_6/r0_111.jpg|apple_6|\n",
      "|s3://ntv-p8/data/apple_6/r0_115.jpg|apple_6|\n",
      "+-----------------------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "---Chargement des images---\n",
      "Temps d'execution 0.03 secondes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 23:53:41.418652: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-19 23:53:41.418702: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-19 23:53:41.418728: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-83-19.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-06-19 23:53:41.419991: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+\n",
      "|            path_img|  categ|    preprossed_image|\n",
      "+--------------------+-------+--------------------+\n",
      "|s3://ntv-p8/data/...|apple_6|[255, 255, 255, 2...|\n",
      "|s3://ntv-p8/data/...|apple_6|[255, 255, 255, 2...|\n",
      "|s3://ntv-p8/data/...|apple_6|[255, 255, 255, 2...|\n",
      "|s3://ntv-p8/data/...|apple_6|[255, 255, 255, 2...|\n",
      "|s3://ntv-p8/data/...|apple_6|[255, 255, 255, 2...|\n",
      "+--------------------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "---Extraction des features---\n",
      "Temps d'execution 3.23 secondes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 23:54:23.306587: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-19 23:54:23.306624: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-19 23:54:25.268053: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-19 23:54:25.268090: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-19 23:54:25.268112: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-83-19.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-06-19 23:54:25.268322: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "5/5 [==============================] - 2s 52ms/step\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------------------+--------------------+\n",
      "|            path_img|          categ|    preprossed_image|            features|\n",
      "+--------------------+---------------+--------------------+--------------------+\n",
      "|s3://ntv-p8/data/...|cabbage_white_1|[255, 255, 255, 2...|[0.0, 3.8330007, ...|\n",
      "|s3://ntv-p8/data/...|        apple_6|[255, 255, 255, 2...|[0.0, 5.48434, 0....|\n",
      "|s3://ntv-p8/data/...|        apple_6|[255, 255, 255, 2...|[0.0, 9.448408, 0...|\n",
      "|s3://ntv-p8/data/...|        apple_6|[255, 255, 255, 2...|[0.0, 0.5607046, ...|\n",
      "|s3://ntv-p8/data/...|        apple_6|[255, 255, 255, 2...|[0.0, 0.9272784, ...|\n",
      "+--------------------+---------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "---Réduction dimmensionnelle---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 23:54:48.478514: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-19 23:54:48.479253: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-19 23:54:48.574153: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-19 23:54:48.574200: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-19 23:54:50.478942: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-19 23:54:50.479033: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-19 23:54:50.479071: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-83-19.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-06-19 23:54:50.479298: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-19 23:54:50.807336: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-19 23:54:50.807379: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-19 23:54:50.807400: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-83-19.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-06-19 23:54:50.808074: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "5/5 [==============================] - 2s 94ms/step\n",
      "5/5 [==============================] - 2s 83ms/step\n",
      "2022-06-19 23:55:13.410599: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-19 23:55:13.410641: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-19 23:55:15.695709: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-19 23:55:15.696227: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-19 23:55:15.696450: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-83-19.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-06-19 23:55:15.696858: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "5/5 [==============================] - 1s 68ms/step\n",
      "5/5 [==============================] - 1s 50ms/step==>              (3 + 1) / 4]\n",
      "5/5 [==============================] - 1s 50ms/step                 (0 + 1) / 1]\n",
      "5/5 [==============================] - 1s 50ms/step                 (0 + 1) / 1]\n",
      "5/5 [==============================] - 1s 78ms/step                 (0 + 2) / \n",
      "5/5 [==============================] - 1s 93ms/step\n",
      "2022-06-19 23:56:44.381011: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-19 23:56:44.381319: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-19 23:56:46.665177: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-19 23:56:46.665693: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-19 23:56:46.665954: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-83-19.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-06-19 23:56:46.666428: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "5/5 [==============================] - 1s 77ms/step\n",
      "5/5 [==============================] - 1s 54ms/step==>              (3 + 1) / \n",
      "5/5 [==============================] - 1s 51ms/step                 (0 + 1) / \n",
      "2022-06-19 23:57:30.179179: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-19 23:57:30.179469: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-19 23:57:32.410159: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-19 23:57:32.410475: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-19 23:57:32.410536: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-83-19.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-06-19 23:57:32.410939: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "5/5 [==============================] - 1s 60ms/step\n",
      "5/5 [==============================] - 2s 67ms/step                 (1 + 2) / \n",
      "5/5 [==============================] - 1s 74ms/step                 (2 + 2) / \n",
      "5/5 [==============================] - 1s 50ms/step==>              (3 + 1) / \n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 composantes principales expliquent au moins 95% de la variance totale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 54ms/step                 (0 + 1) / \n",
      "5/5 [==============================] - 1s 51ms/step                 (0 + 1) / \n",
      "5/5 [==============================] - 1s 80ms/step                 (0 + 2) / \n",
      "5/5 [==============================] - 2s 75ms/step\n",
      "2022-06-19 23:59:54.939807: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-19 23:59:54.940331: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-20 00:00:01.726951: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-20 00:00:01.727483: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-20 00:00:01.727730: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-83-19.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-06-20 00:00:01.728171: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "5/5 [==============================] - 1s 72ms/step\n",
      "5/5 [==============================] - 1s 53ms/step==>              (3 + 1) / \n",
      "5/5 [==============================] - 1s 52ms/step                 (0 + 1) / \n",
      "2022-06-20 00:00:47.477677: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-20 00:00:47.478233: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-20 00:00:53.049991: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-20 00:00:53.050089: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-20 00:00:53.050130: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-83-19.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-06-20 00:00:53.050355: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "5/5 [==============================] - 1s 75ms/step\n",
      "5/5 [==============================] - 2s 65ms/step                 (1 + 2) / \n",
      "5/5 [==============================] - 1s 68ms/step                 (2 + 2) / \n",
      "5/5 [==============================] - 1s 51ms/step==>              (3 + 1) / \n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'execution 444.38 secondes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 52ms/step                 (0 + 1) / \n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------------------+--------------------+--------------------+\n",
      "|            path_img|          categ|    preprossed_image|            features|      feature_reduit|\n",
      "+--------------------+---------------+--------------------+--------------------+--------------------+\n",
      "|s3://ntv-p8/data/...|cabbage_white_1|[255, 255, 255, 2...|[0.0,3.8330006599...|[24.8429349809501...|\n",
      "|s3://ntv-p8/data/...|        apple_6|[255, 255, 255, 2...|[0.0,5.4843401908...|[6.72491747229549...|\n",
      "|s3://ntv-p8/data/...|        apple_6|[255, 255, 255, 2...|[0.0,9.4484081268...|[11.8238296691685...|\n",
      "|s3://ntv-p8/data/...|        apple_6|[255, 255, 255, 2...|[0.0,0.5607045888...|[4.53909093375285...|\n",
      "|s3://ntv-p8/data/...|        apple_6|[255, 255, 255, 2...|[0.0,0.9272783994...|[3.77244666109634...|\n",
      "+--------------------+---------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "----Enregistrement----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 00:03:46.806357: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-20 00:03:46.806937: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-20 00:03:46.807285: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-20 00:03:46.807496: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-20 00:03:50.084687: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-20 00:03:50.085114: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-20 00:03:50.085295: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-83-19.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-06-20 00:03:50.085660: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-20 00:03:50.287129: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-20 00:03:50.287264: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-20 00:03:50.287304: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-83-19.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-06-20 00:03:50.287549: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "5/5 [==============================] - 1s 79ms/step\n",
      "5/5 [==============================] - 1s 62ms/step\n",
      "5/5 [==============================] - 1s 71ms/step                 (2 + 2) / \n",
      "5/5 [==============================] - 1s 53ms/step==>              (3 + 1) / \n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'execution 86.23 secondes\n",
      "Save on S3 done.\n",
      "##############################\n"
     ]
    }
   ],
   "source": [
    "# Définis le chemin d'accès au dossier des images sur local ou cloud AWS\n",
    "local = 'False'\n",
    "folder = 's3://ntv-p8/data/'\n",
    "\n",
    "\n",
    "print(\"---Liste des images---\")\n",
    "df = load_data(folder)\n",
    "df.show(5, False)\n",
    "\n",
    "\n",
    "print(\"----Extraction des catégories images-----\")\n",
    "start_time = time.time()\n",
    "udf_categ = udf(extract_categ, StringType())\n",
    "df = df.withColumn(\"categ\", udf_categ('path_img'))\n",
    "print(\"Temps d'execution {:.2f} secondes\".format(time.time() - start_time))\n",
    "df.show(5, False)\n",
    "\n",
    "\n",
    "print(\"---Chargement des images---\")\n",
    "start_time = time.time()\n",
    "ud_f = udf(lambda x: np.asarray(preprocess_image(x)).flatten().tolist())\n",
    "df = df = df.withColumn('preprossed_image', ud_f('path_img'))\n",
    "print(\"Temps d'execution {:.2f} secondes\".format(time.time() - start_time))\n",
    "df.show(5)\n",
    "\n",
    "\n",
    "print(\"---Extraction des features---\")\n",
    "start_time = time.time()\n",
    "model = ResNet50(include_top=False)    # Instanciation du modèle\n",
    "bc_model_weights = sc.broadcast(model.get_weights()) # Permettre aux workers Spark d'accéder aux poids utilisés par le modèle\n",
    "df = df.repartition(4).select(col(\"path_img\"),\n",
    "                              col(\"categ\"),\n",
    "                              col(\"preprossed_image\"),\n",
    "                              featurize_udf(\"path_img\").alias(\"features\"))\n",
    "print(\"Temps d'execution {:.2f} secondes\".format(time.time() - start_time))\n",
    "df.show(5)\n",
    "\n",
    "\n",
    "\n",
    "print(\"---Réduction dimmensionnelle---\")\n",
    "start_time = time.time()\n",
    "df = reduction_dimension(df)\n",
    "df = df.select('path_img', 'categ', 'preprossed_image', 'features', 'feature_reduit')\n",
    "print(\"Temps d'execution {:.2f} secondes\".format(time.time() - start_time))\n",
    "df.show(5)\n",
    "\n",
    "\n",
    "print('----Enregistrement----')\n",
    "save_data(df)\n",
    "if local == 'True':\n",
    "    print('Save on local disk done.')\n",
    "else:\n",
    "    print('Save on S3 done.')\n",
    "print('#'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdafa8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
